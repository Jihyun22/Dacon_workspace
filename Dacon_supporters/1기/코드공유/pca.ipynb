{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import multiprocessing # 여러 개의 일꾼 (cpu)들에게 작업을 분산시키는 역할\n",
    "from multiprocessing import Pool \n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "from data_loader_v2 import data_loader_v2\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib # 모델을 저장하고 불러오는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'data/train/'\n",
    "test_folder = 'data/test/'\n",
    "train_label_path = 'data/train_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)\n",
    "train_label = pd.read_csv(train_label_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이콘 제공\n",
    "def data_loader_all_v2(func, files, folder='', train_label=None, event_time=10, nrows=60):   \n",
    "    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)     \n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes=multiprocessing.cpu_count()) \n",
    "        df_list = list(pool.imap(func_fixed, files)) \n",
    "        pool.close()\n",
    "        pool.join()        \n",
    "    combined_df = pd.concat(df_list)    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label, event_time=10, nrows=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_loader_all_v2(data_loader_v2, test_list, folder=test_folder, train_label=None, event_time=20, nrows=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 프레임생성\n",
    "X_train = train.drop(['label'], axis=1)\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA 차원축소 압축효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV3인 경우 개별 fold 세트별 정확도 :  [0.7795827  0.80259345 0.79941585]\n",
      "평균 정확도 : 0.7939\n"
     ]
    }
   ],
   "source": [
    "#차원축소 분류 예측 성능 평가\n",
    "\n",
    "#원본 데이터세트\n",
    "#랜덤 포레스트 이용해 타깃 값이 디폴트 값을 3개 교차 검증 세트로 분류 예측\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rcf=RandomForestClassifier(n_estimators=300, random_state=156)\n",
    "scores = cross_val_score(rcf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "print('CV3인 경우 개별 fold 세트별 정확도 : ', scores)\n",
    "print('평균 정확도 : {0:.4f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV3인 경우 PCA변환된 개별 fold 세트별 정확도 :  [0.64587394 0.64872501 0.66316174]\n",
      "PCA 변환 데이터 세트 평균 정확도 : 0.6526\n"
     ]
    }
   ],
   "source": [
    "#PCA차원축소\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#원본스케일링\n",
    "scaler = StandardScaler()\n",
    "df_scaled=scaler.fit_transform(X_train)\n",
    "#컴포넌트 임의 6개 선정\n",
    "pca=PCA(n_components=6)\n",
    "df_pca = pca.fit_transform(df_scaled)\n",
    "scores_pca = cross_val_score(rcf,df_pca, y_train, scoring='accuracy', cv=3)\n",
    "print('CV3인 경우 PCA변환된 개별 fold 세트별 정확도 : ', scores_pca)\n",
    "print('PCA 변환 데이터 세트 평균 정확도 : {0:.4f}'.format(np.mean(scores_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jih02\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV3인 경우 lda변환된 개별 fold 세트별 정확도 :  [0.05183741 0.05201391 0.05213582]\n",
      "lda 변환 데이터 세트 평균 정확도 : 0.0520\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#원본스케일링\n",
    "scaler = StandardScaler()\n",
    "df_scaled=scaler.fit_transform(X_train)\n",
    "\n",
    "#컴포넌트 임의 6개 선정\n",
    "lda=LinearDiscriminantAnalysis(n_components=2)\n",
    "lda.fit(df_scaled, train.label)\n",
    "df_lda=lda.transform(df_scaled)\n",
    "scores_lda = cross_val_score(rcf, df_lda, y_train, scoring='accuracy', cv=3)\n",
    "print('CV3인 경우 lda변환된 개별 fold 세트별 정확도 : ', scores_lda)\n",
    "print('lda 변환 데이터 세트 평균 정확도 : {0:.4f}'.format(np.mean(scores_lda)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
